{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T03:57:35.459055Z",
     "start_time": "2018-05-02T03:57:32.757602Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kentaro.nakanishi.dvs/.anyenv/envs/pyenv/versions/3.5.2/lib/python3.5/importlib/_bootstrap.py:222: RuntimeWarning: compiletime version 3.6 of module 'tensorflow.python.framework.fast_tensor_util' does not match runtime version 3.5\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T03:57:36.012133Z",
     "start_time": "2018-05-02T03:57:35.461307Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting data/train-images-idx3-ubyte.gz\n",
      "Extracting data/train-labels-idx1-ubyte.gz\n",
      "Extracting data/t10k-images-idx3-ubyte.gz\n",
      "Extracting data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"data/\", one_hot=True)\n",
    "test_images = mnist.test.images\n",
    "test_labels = mnist.test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T03:58:04.194738Z",
     "start_time": "2018-05-02T03:58:04.188221Z"
    }
   },
   "outputs": [],
   "source": [
    "# constant\n",
    "\n",
    "num_inputs = 784  # 28*28\n",
    "num_units = 256\n",
    "num_outputs = 10\n",
    "num_layers = 1\n",
    "batch_size = 64\n",
    "learning_rate = 0.001\n",
    "num_epocs = 5000\n",
    "step_to_print = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T03:57:36.026222Z",
     "start_time": "2018-05-02T03:57:36.023089Z"
    }
   },
   "outputs": [],
   "source": [
    "myfloat = tf.float32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T03:57:36.036807Z",
     "start_time": "2018-05-02T03:57:36.028816Z"
    }
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=myfloat, shape=[None, num_inputs])\n",
    "y = tf.placeholder(dtype=myfloat, shape=[None, num_outputs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T03:57:36.066133Z",
     "start_time": "2018-05-02T03:57:36.039139Z"
    }
   },
   "outputs": [],
   "source": [
    "# 一層\n",
    "w_1 = tf.Variable(tf.truncated_normal([num_inputs, num_units], stddev=0.1), dtype=myfloat, name='w_1')\n",
    "b_1 = tf.Variable(tf.zeros([num_units]), dtype=myfloat, name='b_1')\n",
    "h_1 = tf.nn.relu(tf.matmul(x, w_1) + b_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T03:57:36.120843Z",
     "start_time": "2018-05-02T03:57:36.068107Z"
    }
   },
   "outputs": [],
   "source": [
    "w_2 = tf.Variable(tf.truncated_normal([num_units, num_units], stddev=0.1), dtype=myfloat, name='w_2')\n",
    "b_2 = tf.Variable(tf.zeros([num_units]), dtype=myfloat, name='b_2')\n",
    "h_2 = tf.nn.relu(tf.matmul(h_1, w_2) + b_2)\n",
    "w_3 = tf.Variable(tf.truncated_normal([num_units, num_outputs], stddev=0.1), dtype=myfloat, name='w_3')\n",
    "b_3 = tf.Variable(tf.zeros([num_outputs]), dtype=myfloat, name='b_3')\n",
    "out = tf.nn.softmax(tf.matmul(h_2, w_3) + b_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T03:57:36.488059Z",
     "start_time": "2018-05-02T03:57:36.123830Z"
    }
   },
   "outputs": [],
   "source": [
    "train_loss = tf.reduce_sum(tf.square(y - out))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate)\n",
    "params = tf.trainable_variables()\n",
    "gradients = tf.gradients(train_loss, params)\n",
    "\n",
    "training = optimizer.apply_gradients(zip(gradients, params))\n",
    "\n",
    "grad_norm = [tf.norm(g) for g in gradients]\n",
    "grad_norm_sum = tf.reduce_sum(grad_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T03:57:36.507406Z",
     "start_time": "2018-05-02T03:57:36.490532Z"
    }
   },
   "outputs": [],
   "source": [
    "correct = tf.equal(tf.argmax(out, 1), tf.argmax(y, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct, myfloat))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T03:57:36.523736Z",
     "start_time": "2018-05-02T03:57:36.509674Z"
    }
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "with tf.name_scope('summary'):\n",
    "    summary_loss = tf.summary.scalar('loss', train_loss)\n",
    "    summary_grad = tf.summary.scalar('gradients', grad_norm_sum)\n",
    "    summary_acc = tf.summary.scalar('accuracy', accuracy)\n",
    "    merged_summary = tf.summary.merge_all()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T03:57:36.529579Z",
     "start_time": "2018-05-02T03:57:36.525905Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "now = datetime.now()\n",
    "logdir = 'logs/mnist_dnn/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-02T03:58:50.115546Z",
     "start_time": "2018-05-02T03:58:08.893119Z"
    },
    "lines_to_next_cell": 0
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 0 , loss : 58.9544 , accuracy:  0.0886\n",
      "step : 10 , loss : 50.6051 , accuracy:  0.544\n",
      "step : 20 , loss : 38.6436 , accuracy:  0.6679\n",
      "step : 30 , loss : 25.2187 , accuracy:  0.7726\n",
      "step : 40 , loss : 21.6005 , accuracy:  0.8276\n",
      "step : 50 , loss : 15.52 , accuracy:  0.8405\n",
      "step : 60 , loss : 15.1151 , accuracy:  0.8571\n",
      "step : 70 , loss : 13.1278 , accuracy:  0.8694\n",
      "step : 80 , loss : 9.22161 , accuracy:  0.8815\n",
      "step : 90 , loss : 10.1506 , accuracy:  0.8845\n",
      "step : 100 , loss : 8.59643 , accuracy:  0.8953\n",
      "step : 110 , loss : 6.15303 , accuracy:  0.8977\n",
      "step : 120 , loss : 9.43832 , accuracy:  0.9053\n",
      "step : 130 , loss : 10.3868 , accuracy:  0.9056\n",
      "step : 140 , loss : 6.37034 , accuracy:  0.9035\n",
      "step : 150 , loss : 6.32708 , accuracy:  0.9149\n",
      "step : 160 , loss : 9.71037 , accuracy:  0.916\n",
      "step : 170 , loss : 7.90262 , accuracy:  0.9147\n",
      "step : 180 , loss : 11.7068 , accuracy:  0.9155\n",
      "step : 190 , loss : 6.72824 , accuracy:  0.9138\n",
      "step : 200 , loss : 15.7144 , accuracy:  0.9192\n",
      "step : 210 , loss : 6.05526 , accuracy:  0.9177\n",
      "step : 220 , loss : 10.1879 , accuracy:  0.9244\n",
      "step : 230 , loss : 5.54498 , accuracy:  0.923\n",
      "step : 240 , loss : 11.9893 , accuracy:  0.9157\n",
      "step : 250 , loss : 6.41494 , accuracy:  0.9183\n",
      "step : 260 , loss : 9.8868 , accuracy:  0.9265\n",
      "step : 270 , loss : 5.44595 , accuracy:  0.9254\n",
      "step : 280 , loss : 4.45071 , accuracy:  0.9265\n",
      "step : 290 , loss : 9.12756 , accuracy:  0.9213\n",
      "step : 300 , loss : 9.60643 , accuracy:  0.9339\n",
      "step : 310 , loss : 7.20274 , accuracy:  0.9294\n",
      "step : 320 , loss : 7.89495 , accuracy:  0.9278\n",
      "step : 330 , loss : 2.76205 , accuracy:  0.9327\n",
      "step : 340 , loss : 10.8497 , accuracy:  0.9361\n",
      "step : 350 , loss : 4.45794 , accuracy:  0.9301\n",
      "step : 360 , loss : 5.50355 , accuracy:  0.9382\n",
      "step : 370 , loss : 3.57566 , accuracy:  0.9351\n",
      "step : 380 , loss : 10.7506 , accuracy:  0.9274\n",
      "step : 390 , loss : 7.41336 , accuracy:  0.9215\n",
      "step : 400 , loss : 9.12222 , accuracy:  0.9264\n",
      "step : 410 , loss : 13.5184 , accuracy:  0.9337\n",
      "step : 420 , loss : 5.60649 , accuracy:  0.9408\n",
      "step : 430 , loss : 3.91421 , accuracy:  0.9405\n",
      "step : 440 , loss : 4.74155 , accuracy:  0.9351\n",
      "step : 450 , loss : 2.57798 , accuracy:  0.9329\n",
      "step : 460 , loss : 5.42241 , accuracy:  0.933\n",
      "step : 470 , loss : 2.6822 , accuracy:  0.9342\n",
      "step : 480 , loss : 5.17438 , accuracy:  0.9433\n",
      "step : 490 , loss : 6.55367 , accuracy:  0.9407\n",
      "step : 500 , loss : 4.93557 , accuracy:  0.9414\n",
      "step : 510 , loss : 8.25447 , accuracy:  0.9405\n",
      "step : 520 , loss : 11.4497 , accuracy:  0.9438\n",
      "step : 530 , loss : 4.8129 , accuracy:  0.9402\n",
      "step : 540 , loss : 7.18644 , accuracy:  0.9405\n",
      "step : 550 , loss : 7.4431 , accuracy:  0.9437\n",
      "step : 560 , loss : 6.88218 , accuracy:  0.9481\n",
      "step : 570 , loss : 5.13966 , accuracy:  0.9462\n",
      "step : 580 , loss : 5.18294 , accuracy:  0.9451\n",
      "step : 590 , loss : 4.26768 , accuracy:  0.9488\n",
      "step : 600 , loss : 9.31333 , accuracy:  0.9438\n",
      "step : 610 , loss : 6.72563 , accuracy:  0.9482\n",
      "step : 620 , loss : 5.18293 , accuracy:  0.945\n",
      "step : 630 , loss : 2.07276 , accuracy:  0.9465\n",
      "step : 640 , loss : 7.50262 , accuracy:  0.9449\n",
      "step : 650 , loss : 4.26083 , accuracy:  0.9487\n",
      "step : 660 , loss : 4.99805 , accuracy:  0.9465\n",
      "step : 670 , loss : 3.76514 , accuracy:  0.9494\n",
      "step : 680 , loss : 5.17415 , accuracy:  0.9469\n",
      "step : 690 , loss : 11.5507 , accuracy:  0.9488\n",
      "step : 700 , loss : 6.88766 , accuracy:  0.9525\n",
      "step : 710 , loss : 8.23392 , accuracy:  0.9434\n",
      "step : 720 , loss : 7.04821 , accuracy:  0.9487\n",
      "step : 730 , loss : 4.57059 , accuracy:  0.9522\n",
      "step : 740 , loss : 6.20559 , accuracy:  0.9485\n",
      "step : 750 , loss : 3.53414 , accuracy:  0.9542\n",
      "step : 760 , loss : 5.17059 , accuracy:  0.9532\n",
      "step : 770 , loss : 9.47001 , accuracy:  0.9484\n",
      "step : 780 , loss : 4.88913 , accuracy:  0.9496\n",
      "step : 790 , loss : 8.18128 , accuracy:  0.9516\n",
      "step : 800 , loss : 1.63781 , accuracy:  0.9504\n",
      "step : 810 , loss : 0.733411 , accuracy:  0.9477\n",
      "step : 820 , loss : 2.87078 , accuracy:  0.9509\n",
      "step : 830 , loss : 5.29631 , accuracy:  0.9456\n",
      "step : 840 , loss : 2.17793 , accuracy:  0.9536\n",
      "step : 850 , loss : 9.20764 , accuracy:  0.9573\n",
      "step : 860 , loss : 4.04535 , accuracy:  0.9539\n",
      "step : 870 , loss : 1.08995 , accuracy:  0.9525\n",
      "step : 880 , loss : 3.15484 , accuracy:  0.9557\n",
      "step : 890 , loss : 7.03709 , accuracy:  0.9588\n",
      "step : 900 , loss : 4.58732 , accuracy:  0.9521\n",
      "step : 910 , loss : 2.66667 , accuracy:  0.9556\n",
      "step : 920 , loss : 1.77689 , accuracy:  0.9485\n",
      "step : 930 , loss : 7.83297 , accuracy:  0.9527\n",
      "step : 940 , loss : 3.74891 , accuracy:  0.9587\n",
      "step : 950 , loss : 5.00911 , accuracy:  0.9552\n",
      "step : 960 , loss : 5.6164 , accuracy:  0.9549\n",
      "step : 970 , loss : 4.60653 , accuracy:  0.9551\n",
      "step : 980 , loss : 1.53029 , accuracy:  0.9568\n",
      "step : 990 , loss : 4.5298 , accuracy:  0.9525\n",
      "step : 1000 , loss : 8.33401 , accuracy:  0.9551\n",
      "step : 1010 , loss : 1.02946 , accuracy:  0.9545\n",
      "step : 1020 , loss : 4.85804 , accuracy:  0.9547\n",
      "step : 1030 , loss : 7.3278 , accuracy:  0.9541\n",
      "step : 1040 , loss : 4.15228 , accuracy:  0.955\n",
      "step : 1050 , loss : 1.28166 , accuracy:  0.9515\n",
      "step : 1060 , loss : 4.2238 , accuracy:  0.9572\n",
      "step : 1070 , loss : 7.58896 , accuracy:  0.9569\n",
      "step : 1080 , loss : 4.93534 , accuracy:  0.9545\n",
      "step : 1090 , loss : 2.79671 , accuracy:  0.9543\n",
      "step : 1100 , loss : 10.1494 , accuracy:  0.9588\n",
      "step : 1110 , loss : 4.51197 , accuracy:  0.9596\n",
      "step : 1120 , loss : 2.1785 , accuracy:  0.9568\n",
      "step : 1130 , loss : 1.32224 , accuracy:  0.9575\n",
      "step : 1140 , loss : 4.35342 , accuracy:  0.9577\n",
      "step : 1150 , loss : 4.64248 , accuracy:  0.9593\n",
      "step : 1160 , loss : 2.99826 , accuracy:  0.9596\n",
      "step : 1170 , loss : 3.96634 , accuracy:  0.959\n",
      "step : 1180 , loss : 2.36388 , accuracy:  0.9599\n",
      "step : 1190 , loss : 4.24896 , accuracy:  0.9592\n",
      "step : 1200 , loss : 3.15337 , accuracy:  0.9555\n",
      "step : 1210 , loss : 4.71399 , accuracy:  0.9565\n",
      "step : 1220 , loss : 0.692438 , accuracy:  0.96\n",
      "step : 1230 , loss : 3.93941 , accuracy:  0.9561\n",
      "step : 1240 , loss : 3.11973 , accuracy:  0.9587\n",
      "step : 1250 , loss : 4.57938 , accuracy:  0.9575\n",
      "step : 1260 , loss : 2.32846 , accuracy:  0.9593\n",
      "step : 1270 , loss : 3.08345 , accuracy:  0.9583\n",
      "step : 1280 , loss : 8.43651 , accuracy:  0.9606\n",
      "step : 1290 , loss : 5.87179 , accuracy:  0.9585\n",
      "step : 1300 , loss : 6.63696 , accuracy:  0.9569\n",
      "step : 1310 , loss : 1.65898 , accuracy:  0.9608\n",
      "step : 1320 , loss : 1.02154 , accuracy:  0.9639\n",
      "step : 1330 , loss : 5.18045 , accuracy:  0.9599\n",
      "step : 1340 , loss : 6.08018 , accuracy:  0.9641\n",
      "step : 1350 , loss : 1.97371 , accuracy:  0.9646\n",
      "step : 1360 , loss : 6.22059 , accuracy:  0.9624\n",
      "step : 1370 , loss : 2.1433 , accuracy:  0.9651\n",
      "step : 1380 , loss : 6.94369 , accuracy:  0.9586\n",
      "step : 1390 , loss : 4.07834 , accuracy:  0.9632\n",
      "step : 1400 , loss : 3.63997 , accuracy:  0.9572\n",
      "step : 1410 , loss : 5.26699 , accuracy:  0.9615\n",
      "step : 1420 , loss : 4.3192 , accuracy:  0.9604\n",
      "step : 1430 , loss : 4.73495 , accuracy:  0.9636\n",
      "step : 1440 , loss : 3.94444 , accuracy:  0.9588\n",
      "step : 1450 , loss : 2.777 , accuracy:  0.9601\n",
      "step : 1460 , loss : 3.44115 , accuracy:  0.9654\n",
      "step : 1470 , loss : 4.62736 , accuracy:  0.9643\n",
      "step : 1480 , loss : 2.2162 , accuracy:  0.966\n",
      "step : 1490 , loss : 1.48425 , accuracy:  0.9674\n",
      "step : 1500 , loss : 4.12384 , accuracy:  0.9658\n",
      "step : 1510 , loss : 2.14286 , accuracy:  0.9655\n",
      "step : 1520 , loss : 2.96377 , accuracy:  0.9632\n",
      "step : 1530 , loss : 1.26968 , accuracy:  0.9672\n",
      "step : 1540 , loss : 4.0218 , accuracy:  0.9644\n",
      "step : 1550 , loss : 3.50727 , accuracy:  0.9672\n",
      "step : 1560 , loss : 0.512005 , accuracy:  0.9584\n",
      "step : 1570 , loss : 0.621058 , accuracy:  0.9684\n",
      "step : 1580 , loss : 5.6594 , accuracy:  0.9657\n",
      "step : 1590 , loss : 2.73627 , accuracy:  0.9669\n",
      "step : 1600 , loss : 1.2324 , accuracy:  0.9671\n",
      "step : 1610 , loss : 1.69388 , accuracy:  0.9658\n",
      "step : 1620 , loss : 3.17684 , accuracy:  0.9649\n",
      "step : 1630 , loss : 1.51947 , accuracy:  0.9666\n",
      "step : 1640 , loss : 5.51205 , accuracy:  0.9657\n",
      "step : 1650 , loss : 0.51101 , accuracy:  0.9668\n",
      "step : 1660 , loss : 0.535837 , accuracy:  0.9659\n",
      "step : 1670 , loss : 3.2304 , accuracy:  0.9663\n",
      "step : 1680 , loss : 3.56056 , accuracy:  0.9688\n",
      "step : 1690 , loss : 2.53609 , accuracy:  0.9674\n",
      "step : 1700 , loss : 1.57106 , accuracy:  0.967\n",
      "step : 1710 , loss : 1.84965 , accuracy:  0.9674\n",
      "step : 1720 , loss : 1.20445 , accuracy:  0.9658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 1730 , loss : 2.97258 , accuracy:  0.9652\n",
      "step : 1740 , loss : 1.62622 , accuracy:  0.9642\n",
      "step : 1750 , loss : 1.71371 , accuracy:  0.9592\n",
      "step : 1760 , loss : 4.41024 , accuracy:  0.9612\n",
      "step : 1770 , loss : 3.47737 , accuracy:  0.966\n",
      "step : 1780 , loss : 1.38311 , accuracy:  0.9676\n",
      "step : 1790 , loss : 2.34666 , accuracy:  0.967\n",
      "step : 1800 , loss : 2.40951 , accuracy:  0.968\n",
      "step : 1810 , loss : 7.29261 , accuracy:  0.9671\n",
      "step : 1820 , loss : 0.348086 , accuracy:  0.9668\n",
      "step : 1830 , loss : 3.90744 , accuracy:  0.9687\n",
      "step : 1840 , loss : 3.62095 , accuracy:  0.9668\n",
      "step : 1850 , loss : 2.23114 , accuracy:  0.9661\n",
      "step : 1860 , loss : 3.67999 , accuracy:  0.9684\n",
      "step : 1870 , loss : 3.14292 , accuracy:  0.9643\n",
      "step : 1880 , loss : 2.96037 , accuracy:  0.9661\n",
      "step : 1890 , loss : 2.68659 , accuracy:  0.9688\n",
      "step : 1900 , loss : 4.20217 , accuracy:  0.9645\n",
      "step : 1910 , loss : 5.61062 , accuracy:  0.9674\n",
      "step : 1920 , loss : 0.0748447 , accuracy:  0.9666\n",
      "step : 1930 , loss : 0.258594 , accuracy:  0.9648\n",
      "step : 1940 , loss : 2.568 , accuracy:  0.9587\n",
      "step : 1950 , loss : 5.03525 , accuracy:  0.9613\n",
      "step : 1960 , loss : 2.54345 , accuracy:  0.9651\n",
      "step : 1970 , loss : 2.34162 , accuracy:  0.9673\n",
      "step : 1980 , loss : 1.66537 , accuracy:  0.9689\n",
      "step : 1990 , loss : 4.2827 , accuracy:  0.9665\n",
      "step : 2000 , loss : 6.79929 , accuracy:  0.9625\n",
      "step : 2010 , loss : 2.25095 , accuracy:  0.9684\n",
      "step : 2020 , loss : 1.69631 , accuracy:  0.9702\n",
      "step : 2030 , loss : 2.02833 , accuracy:  0.9677\n",
      "step : 2040 , loss : 3.02935 , accuracy:  0.9691\n",
      "step : 2050 , loss : 2.389 , accuracy:  0.9676\n",
      "step : 2060 , loss : 2.8752 , accuracy:  0.9682\n",
      "step : 2070 , loss : 2.79733 , accuracy:  0.9666\n",
      "step : 2080 , loss : 5.64634 , accuracy:  0.9674\n",
      "step : 2090 , loss : 0.249567 , accuracy:  0.9711\n",
      "step : 2100 , loss : 6.10678 , accuracy:  0.9673\n",
      "step : 2110 , loss : 3.07199 , accuracy:  0.9667\n",
      "step : 2120 , loss : 7.29339 , accuracy:  0.9659\n",
      "step : 2130 , loss : 0.939229 , accuracy:  0.9661\n",
      "step : 2140 , loss : 5.86094 , accuracy:  0.9663\n",
      "step : 2150 , loss : 3.04383 , accuracy:  0.968\n",
      "step : 2160 , loss : 0.760165 , accuracy:  0.9665\n",
      "step : 2170 , loss : 4.38177 , accuracy:  0.9622\n",
      "step : 2180 , loss : 1.35594 , accuracy:  0.9646\n",
      "step : 2190 , loss : 2.23998 , accuracy:  0.9669\n",
      "step : 2200 , loss : 2.8081 , accuracy:  0.9685\n",
      "step : 2210 , loss : 6.20292 , accuracy:  0.969\n",
      "step : 2220 , loss : 2.39718 , accuracy:  0.9693\n",
      "step : 2230 , loss : 3.64279 , accuracy:  0.9673\n",
      "step : 2240 , loss : 1.47956 , accuracy:  0.9671\n",
      "step : 2250 , loss : 2.90962 , accuracy:  0.9666\n",
      "step : 2260 , loss : 2.23823 , accuracy:  0.9662\n",
      "step : 2270 , loss : 1.81778 , accuracy:  0.9684\n",
      "step : 2280 , loss : 1.86271 , accuracy:  0.9679\n",
      "step : 2290 , loss : 0.855288 , accuracy:  0.9687\n",
      "step : 2300 , loss : 2.7698 , accuracy:  0.9728\n",
      "step : 2310 , loss : 0.11924 , accuracy:  0.9702\n",
      "step : 2320 , loss : 5.98091 , accuracy:  0.9698\n",
      "step : 2330 , loss : 2.56593 , accuracy:  0.9706\n",
      "step : 2340 , loss : 2.08137 , accuracy:  0.9701\n",
      "step : 2350 , loss : 1.51482 , accuracy:  0.97\n",
      "step : 2360 , loss : 2.71854 , accuracy:  0.9718\n",
      "step : 2370 , loss : 0.170714 , accuracy:  0.9712\n",
      "step : 2380 , loss : 2.24968 , accuracy:  0.9699\n",
      "step : 2390 , loss : 2.27645 , accuracy:  0.9724\n",
      "step : 2400 , loss : 5.00846 , accuracy:  0.9714\n",
      "step : 2410 , loss : 1.96625 , accuracy:  0.9692\n",
      "step : 2420 , loss : 1.77369 , accuracy:  0.9697\n",
      "step : 2430 , loss : 3.2631 , accuracy:  0.9689\n",
      "step : 2440 , loss : 1.78759 , accuracy:  0.9723\n",
      "step : 2450 , loss : 5.3467 , accuracy:  0.9708\n",
      "step : 2460 , loss : 0.910018 , accuracy:  0.9643\n",
      "step : 2470 , loss : 2.25148 , accuracy:  0.9711\n",
      "step : 2480 , loss : 3.17794 , accuracy:  0.9688\n",
      "step : 2490 , loss : 1.38386 , accuracy:  0.9707\n",
      "step : 2500 , loss : 0.617307 , accuracy:  0.9721\n",
      "step : 2510 , loss : 1.18861 , accuracy:  0.9707\n",
      "step : 2520 , loss : 5.13952 , accuracy:  0.9724\n",
      "step : 2530 , loss : 2.95795 , accuracy:  0.9709\n",
      "step : 2540 , loss : 0.566998 , accuracy:  0.97\n",
      "step : 2550 , loss : 1.22327 , accuracy:  0.9704\n",
      "step : 2560 , loss : 0.730109 , accuracy:  0.9682\n",
      "step : 2570 , loss : 1.90663 , accuracy:  0.97\n",
      "step : 2580 , loss : 0.386998 , accuracy:  0.9697\n",
      "step : 2590 , loss : 1.37175 , accuracy:  0.9696\n",
      "step : 2600 , loss : 3.31418 , accuracy:  0.9707\n",
      "step : 2610 , loss : 6.56767 , accuracy:  0.969\n",
      "step : 2620 , loss : 4.14633 , accuracy:  0.9709\n",
      "step : 2630 , loss : 1.47668 , accuracy:  0.9705\n",
      "step : 2640 , loss : 2.87339 , accuracy:  0.9697\n",
      "step : 2650 , loss : 2.29468 , accuracy:  0.9722\n",
      "step : 2660 , loss : 1.55381 , accuracy:  0.9719\n",
      "step : 2670 , loss : 1.44311 , accuracy:  0.9735\n",
      "step : 2680 , loss : 2.18001 , accuracy:  0.9714\n",
      "step : 2690 , loss : 3.01414 , accuracy:  0.9721\n",
      "step : 2700 , loss : 0.999343 , accuracy:  0.9724\n",
      "step : 2710 , loss : 2.71257 , accuracy:  0.972\n",
      "step : 2720 , loss : 2.20055 , accuracy:  0.9703\n",
      "step : 2730 , loss : 2.23342 , accuracy:  0.9725\n",
      "step : 2740 , loss : 1.39814 , accuracy:  0.9728\n",
      "step : 2750 , loss : 2.18468 , accuracy:  0.9704\n",
      "step : 2760 , loss : 2.4962 , accuracy:  0.971\n",
      "step : 2770 , loss : 0.836836 , accuracy:  0.9718\n",
      "step : 2780 , loss : 3.77538 , accuracy:  0.9697\n",
      "step : 2790 , loss : 5.27573 , accuracy:  0.9691\n",
      "step : 2800 , loss : 3.19502 , accuracy:  0.9698\n",
      "step : 2810 , loss : 0.00993931 , accuracy:  0.9685\n",
      "step : 2820 , loss : 3.47562 , accuracy:  0.9706\n",
      "step : 2830 , loss : 5.64289 , accuracy:  0.969\n",
      "step : 2840 , loss : 0.539127 , accuracy:  0.9713\n",
      "step : 2850 , loss : 5.2659 , accuracy:  0.9677\n",
      "step : 2860 , loss : 5.40678 , accuracy:  0.9735\n",
      "step : 2870 , loss : 0.0481467 , accuracy:  0.9696\n",
      "step : 2880 , loss : 5.90954 , accuracy:  0.9706\n",
      "step : 2890 , loss : 1.85182 , accuracy:  0.9676\n",
      "step : 2900 , loss : 1.49203 , accuracy:  0.9726\n",
      "step : 2910 , loss : 3.92332 , accuracy:  0.9725\n",
      "step : 2920 , loss : 1.0975 , accuracy:  0.9708\n",
      "step : 2930 , loss : 2.06675 , accuracy:  0.9724\n",
      "step : 2940 , loss : 0.484888 , accuracy:  0.9723\n",
      "step : 2950 , loss : 3.8439 , accuracy:  0.974\n",
      "step : 2960 , loss : 0.40852 , accuracy:  0.9726\n",
      "step : 2970 , loss : 5.19422 , accuracy:  0.9734\n",
      "step : 2980 , loss : 7.86205 , accuracy:  0.969\n",
      "step : 2990 , loss : 1.93557 , accuracy:  0.9715\n",
      "step : 3000 , loss : 0.220891 , accuracy:  0.9713\n",
      "step : 3010 , loss : 1.65671 , accuracy:  0.9726\n",
      "step : 3020 , loss : 2.52585 , accuracy:  0.9719\n",
      "step : 3030 , loss : 2.50148 , accuracy:  0.9697\n",
      "step : 3040 , loss : 0.372587 , accuracy:  0.9702\n",
      "step : 3050 , loss : 7.5642 , accuracy:  0.9726\n",
      "step : 3060 , loss : 4.37987 , accuracy:  0.9685\n",
      "step : 3070 , loss : 2.61947 , accuracy:  0.9695\n",
      "step : 3080 , loss : 3.72679 , accuracy:  0.9736\n",
      "step : 3090 , loss : 4.83135 , accuracy:  0.9723\n",
      "step : 3100 , loss : 1.73719 , accuracy:  0.9712\n",
      "step : 3110 , loss : 3.2035 , accuracy:  0.9729\n",
      "step : 3120 , loss : 0.0770403 , accuracy:  0.9748\n",
      "step : 3130 , loss : 4.20886 , accuracy:  0.9721\n",
      "step : 3140 , loss : 2.68173 , accuracy:  0.9695\n",
      "step : 3150 , loss : 2.81558 , accuracy:  0.9715\n",
      "step : 3160 , loss : 3.68706 , accuracy:  0.9715\n",
      "step : 3170 , loss : 3.1181 , accuracy:  0.9711\n",
      "step : 3180 , loss : 4.20846 , accuracy:  0.9685\n",
      "step : 3190 , loss : 3.90706 , accuracy:  0.9727\n",
      "step : 3200 , loss : 1.49543 , accuracy:  0.973\n",
      "step : 3210 , loss : 3.45017 , accuracy:  0.9673\n",
      "step : 3220 , loss : 0.55314 , accuracy:  0.9704\n",
      "step : 3230 , loss : 1.25417 , accuracy:  0.9705\n",
      "step : 3240 , loss : 0.322329 , accuracy:  0.9692\n",
      "step : 3250 , loss : 4.42939 , accuracy:  0.9671\n",
      "step : 3260 , loss : 2.88921 , accuracy:  0.9695\n",
      "step : 3270 , loss : 3.43116 , accuracy:  0.97\n",
      "step : 3280 , loss : 3.45581 , accuracy:  0.9696\n",
      "step : 3290 , loss : 0.110137 , accuracy:  0.9711\n",
      "step : 3300 , loss : 0.390051 , accuracy:  0.9732\n",
      "step : 3310 , loss : 2.25194 , accuracy:  0.9725\n",
      "step : 3320 , loss : 1.89389 , accuracy:  0.9727\n",
      "step : 3330 , loss : 2.49839 , accuracy:  0.9724\n",
      "step : 3340 , loss : 0.203903 , accuracy:  0.9715\n",
      "step : 3350 , loss : 0.0489946 , accuracy:  0.9737\n",
      "step : 3360 , loss : 1.74368 , accuracy:  0.9708\n",
      "step : 3370 , loss : 1.19559 , accuracy:  0.9718\n",
      "step : 3380 , loss : 0.4025 , accuracy:  0.9735\n",
      "step : 3390 , loss : 0.245988 , accuracy:  0.9746\n",
      "step : 3400 , loss : 1.07626 , accuracy:  0.972\n",
      "step : 3410 , loss : 1.75043 , accuracy:  0.9742\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step : 3420 , loss : 2.15529 , accuracy:  0.9734\n",
      "step : 3430 , loss : 3.97533 , accuracy:  0.9725\n",
      "step : 3440 , loss : 1.25824 , accuracy:  0.9743\n",
      "step : 3450 , loss : 0.923752 , accuracy:  0.9743\n",
      "step : 3460 , loss : 0.725502 , accuracy:  0.9727\n",
      "step : 3470 , loss : 6.12032 , accuracy:  0.9725\n",
      "step : 3480 , loss : 3.23518 , accuracy:  0.9726\n",
      "step : 3490 , loss : 1.22304 , accuracy:  0.9731\n",
      "step : 3500 , loss : 1.32575 , accuracy:  0.9743\n",
      "step : 3510 , loss : 0.185195 , accuracy:  0.974\n",
      "step : 3520 , loss : 4.83924 , accuracy:  0.9711\n",
      "step : 3530 , loss : 2.1103 , accuracy:  0.9714\n",
      "step : 3540 , loss : 1.80805 , accuracy:  0.972\n",
      "step : 3550 , loss : 0.0228244 , accuracy:  0.9685\n",
      "step : 3560 , loss : 2.96269 , accuracy:  0.9659\n",
      "step : 3570 , loss : 4.22141 , accuracy:  0.9725\n",
      "step : 3580 , loss : 1.45963 , accuracy:  0.9733\n",
      "step : 3590 , loss : 0.124173 , accuracy:  0.9704\n",
      "step : 3600 , loss : 5.11388 , accuracy:  0.97\n",
      "step : 3610 , loss : 0.183523 , accuracy:  0.9733\n",
      "step : 3620 , loss : 0.951247 , accuracy:  0.972\n",
      "step : 3630 , loss : 2.3444 , accuracy:  0.9729\n",
      "step : 3640 , loss : 5.32895 , accuracy:  0.9724\n",
      "step : 3650 , loss : 1.37583 , accuracy:  0.9724\n",
      "step : 3660 , loss : 0.0598576 , accuracy:  0.9718\n",
      "step : 3670 , loss : 3.35892 , accuracy:  0.9699\n",
      "step : 3680 , loss : 1.83156 , accuracy:  0.9724\n",
      "step : 3690 , loss : 1.25087 , accuracy:  0.9712\n",
      "step : 3700 , loss : 2.93917 , accuracy:  0.9733\n",
      "step : 3710 , loss : 0.579455 , accuracy:  0.9736\n",
      "step : 3720 , loss : 0.252336 , accuracy:  0.9737\n",
      "step : 3730 , loss : 4.28892 , accuracy:  0.9731\n",
      "step : 3740 , loss : 0.191695 , accuracy:  0.9732\n",
      "step : 3750 , loss : 0.24288 , accuracy:  0.9721\n",
      "step : 3760 , loss : 1.60859 , accuracy:  0.9733\n",
      "step : 3770 , loss : 2.34137 , accuracy:  0.9727\n",
      "step : 3780 , loss : 2.05098 , accuracy:  0.9721\n",
      "step : 3790 , loss : 4.61635 , accuracy:  0.9736\n",
      "step : 3800 , loss : 1.55166 , accuracy:  0.9718\n",
      "step : 3810 , loss : 2.72755 , accuracy:  0.9701\n",
      "step : 3820 , loss : 4.39098 , accuracy:  0.9729\n",
      "step : 3830 , loss : 2.68306 , accuracy:  0.9729\n",
      "step : 3840 , loss : 2.24259 , accuracy:  0.9731\n",
      "step : 3850 , loss : 0.705508 , accuracy:  0.9742\n",
      "step : 3860 , loss : 0.630244 , accuracy:  0.9749\n",
      "step : 3870 , loss : 1.40717 , accuracy:  0.9741\n",
      "step : 3880 , loss : 1.08598 , accuracy:  0.9711\n",
      "step : 3890 , loss : 0.408896 , accuracy:  0.9751\n",
      "step : 3900 , loss : 1.80666 , accuracy:  0.9742\n",
      "step : 3910 , loss : 2.42444 , accuracy:  0.9746\n",
      "step : 3920 , loss : 0.671903 , accuracy:  0.9752\n",
      "step : 3930 , loss : 0.573949 , accuracy:  0.9743\n",
      "step : 3940 , loss : 2.02616 , accuracy:  0.9746\n",
      "step : 3950 , loss : 3.68001 , accuracy:  0.974\n",
      "step : 3960 , loss : 1.67327 , accuracy:  0.9721\n",
      "step : 3970 , loss : 1.72428 , accuracy:  0.9693\n",
      "step : 3980 , loss : 0.658374 , accuracy:  0.9722\n",
      "step : 3990 , loss : 3.5384 , accuracy:  0.9707\n",
      "step : 4000 , loss : 0.00583537 , accuracy:  0.9732\n",
      "step : 4010 , loss : 3.7616 , accuracy:  0.9683\n",
      "step : 4020 , loss : 0.101386 , accuracy:  0.9706\n",
      "step : 4030 , loss : 0.346092 , accuracy:  0.9707\n",
      "step : 4040 , loss : 0.406742 , accuracy:  0.9697\n",
      "step : 4050 , loss : 1.2689 , accuracy:  0.9718\n",
      "step : 4060 , loss : 2.45974 , accuracy:  0.9713\n",
      "step : 4070 , loss : 7.01726 , accuracy:  0.9765\n",
      "step : 4080 , loss : 2.78908 , accuracy:  0.976\n",
      "step : 4090 , loss : 4.35726 , accuracy:  0.973\n",
      "step : 4100 , loss : 1.05764 , accuracy:  0.9716\n",
      "step : 4110 , loss : 2.00487 , accuracy:  0.9728\n",
      "step : 4120 , loss : 2.8906 , accuracy:  0.9752\n",
      "step : 4130 , loss : 1.02991 , accuracy:  0.9761\n",
      "step : 4140 , loss : 2.43933 , accuracy:  0.9765\n",
      "step : 4150 , loss : 2.07253 , accuracy:  0.9748\n",
      "step : 4160 , loss : 1.46467 , accuracy:  0.9773\n",
      "step : 4170 , loss : 1.896 , accuracy:  0.9749\n",
      "step : 4180 , loss : 0.107747 , accuracy:  0.9747\n",
      "step : 4190 , loss : 2.26364 , accuracy:  0.9714\n",
      "step : 4200 , loss : 0.354134 , accuracy:  0.9746\n",
      "step : 4210 , loss : 2.29953 , accuracy:  0.9721\n",
      "step : 4220 , loss : 0.226311 , accuracy:  0.9722\n",
      "step : 4230 , loss : 3.46237 , accuracy:  0.9737\n",
      "step : 4240 , loss : 2.39552 , accuracy:  0.9738\n",
      "step : 4250 , loss : 0.156564 , accuracy:  0.9751\n",
      "step : 4260 , loss : 0.138746 , accuracy:  0.9737\n",
      "step : 4270 , loss : 3.47471 , accuracy:  0.9737\n",
      "step : 4280 , loss : 0.552077 , accuracy:  0.9737\n",
      "step : 4290 , loss : 0.359164 , accuracy:  0.972\n",
      "step : 4300 , loss : 2.80801 , accuracy:  0.9689\n",
      "step : 4310 , loss : 1.06647 , accuracy:  0.9728\n",
      "step : 4320 , loss : 0.179157 , accuracy:  0.9729\n",
      "step : 4330 , loss : 0.271049 , accuracy:  0.9716\n",
      "step : 4340 , loss : 2.10838 , accuracy:  0.9756\n",
      "step : 4350 , loss : 0.550529 , accuracy:  0.9726\n",
      "step : 4360 , loss : 1.51707 , accuracy:  0.9763\n",
      "step : 4370 , loss : 1.6855 , accuracy:  0.9736\n",
      "step : 4380 , loss : 0.13371 , accuracy:  0.9758\n",
      "step : 4390 , loss : 0.563789 , accuracy:  0.9754\n",
      "step : 4400 , loss : 2.08294 , accuracy:  0.9754\n",
      "step : 4410 , loss : 0.413398 , accuracy:  0.9746\n",
      "step : 4420 , loss : 0.856641 , accuracy:  0.9749\n",
      "step : 4430 , loss : 4.25719 , accuracy:  0.9745\n",
      "step : 4440 , loss : 0.8061 , accuracy:  0.9761\n",
      "step : 4450 , loss : 1.87016 , accuracy:  0.976\n",
      "step : 4460 , loss : 3.47205 , accuracy:  0.9758\n",
      "step : 4470 , loss : 1.09155 , accuracy:  0.9773\n",
      "step : 4480 , loss : 3.94657 , accuracy:  0.975\n",
      "step : 4490 , loss : 0.559119 , accuracy:  0.9726\n",
      "step : 4500 , loss : 0.633487 , accuracy:  0.9757\n",
      "step : 4510 , loss : 2.22694 , accuracy:  0.976\n",
      "step : 4520 , loss : 0.777431 , accuracy:  0.9754\n",
      "step : 4530 , loss : 0.495265 , accuracy:  0.9775\n",
      "step : 4540 , loss : 0.718149 , accuracy:  0.9752\n",
      "step : 4550 , loss : 3.61094 , accuracy:  0.9727\n",
      "step : 4560 , loss : 1.57904 , accuracy:  0.9765\n",
      "step : 4570 , loss : 0.268721 , accuracy:  0.9764\n",
      "step : 4580 , loss : 0.0503608 , accuracy:  0.9756\n",
      "step : 4590 , loss : 1.91778 , accuracy:  0.9763\n",
      "step : 4600 , loss : 0.0730933 , accuracy:  0.9755\n",
      "step : 4610 , loss : 3.4294 , accuracy:  0.9741\n",
      "step : 4620 , loss : 0.418216 , accuracy:  0.9744\n",
      "step : 4630 , loss : 0.0395843 , accuracy:  0.975\n",
      "step : 4640 , loss : 0.377432 , accuracy:  0.9765\n",
      "step : 4650 , loss : 0.553203 , accuracy:  0.9742\n",
      "step : 4660 , loss : 5.33503 , accuracy:  0.9757\n",
      "step : 4670 , loss : 1.28667 , accuracy:  0.9759\n",
      "step : 4680 , loss : 2.34115 , accuracy:  0.9753\n",
      "step : 4690 , loss : 0.347006 , accuracy:  0.9751\n",
      "step : 4700 , loss : 0.248135 , accuracy:  0.9743\n",
      "step : 4710 , loss : 0.832098 , accuracy:  0.9737\n",
      "step : 4720 , loss : 0.187312 , accuracy:  0.9738\n",
      "step : 4730 , loss : 3.14866 , accuracy:  0.9764\n",
      "step : 4740 , loss : 2.12566 , accuracy:  0.9771\n",
      "step : 4750 , loss : 1.0072 , accuracy:  0.9777\n",
      "step : 4760 , loss : 4.39575 , accuracy:  0.9762\n",
      "step : 4770 , loss : 0.937347 , accuracy:  0.977\n",
      "step : 4780 , loss : 0.028667 , accuracy:  0.976\n",
      "step : 4790 , loss : 1.13541 , accuracy:  0.9748\n",
      "step : 4800 , loss : 3.10756 , accuracy:  0.9755\n",
      "step : 4810 , loss : 0.924842 , accuracy:  0.9732\n",
      "step : 4820 , loss : 0.164227 , accuracy:  0.9718\n",
      "step : 4830 , loss : 2.12182 , accuracy:  0.9766\n",
      "step : 4840 , loss : 0.871935 , accuracy:  0.9782\n",
      "step : 4850 , loss : 0.256513 , accuracy:  0.9752\n",
      "step : 4860 , loss : 0.223181 , accuracy:  0.9749\n",
      "step : 4870 , loss : 1.17798 , accuracy:  0.9769\n",
      "step : 4880 , loss : 2.89591 , accuracy:  0.9747\n",
      "step : 4890 , loss : 4.28261 , accuracy:  0.9737\n",
      "step : 4900 , loss : 0.0810372 , accuracy:  0.9733\n",
      "step : 4910 , loss : 1.84626 , accuracy:  0.9776\n",
      "step : 4920 , loss : 3.6261 , accuracy:  0.974\n",
      "step : 4930 , loss : 1.59336 , accuracy:  0.9745\n",
      "step : 4940 , loss : 2.43464 , accuracy:  0.9737\n",
      "step : 4950 , loss : 0.266673 , accuracy:  0.974\n",
      "step : 4960 , loss : 3.1903 , accuracy:  0.9769\n",
      "step : 4970 , loss : 5.8666 , accuracy:  0.9753\n",
      "step : 4980 , loss : 0.525355 , accuracy:  0.9733\n",
      "step : 4990 , loss : 0.497175 , accuracy:  0.9699\n"
     ]
    }
   ],
   "source": [
    "logdir = logdir + now.strftime(\"%Y%m%d-%H%M%S\") + \"/\"\n",
    "with tf.Session() as sess:\n",
    "    writer = tf.summary.FileWriter(logdir, sess.graph)\n",
    "    sess.run(init)\n",
    "    for e in range(num_epocs):\n",
    "        xdata, ydata = mnist.train.next_batch(batch_size)\n",
    "        l, _, smr = sess.run([train_loss, training, merged_summary], feed_dict={\n",
    "            x: xdata,\n",
    "            y: ydata\n",
    "        })\n",
    "        if e % step_to_print == 0:\n",
    "            acc = sess.run(accuracy, feed_dict={\n",
    "                x: test_images,\n",
    "                y: test_labels\n",
    "            })\n",
    "            print('step :', e, ', loss :', l, ', accuracy: ', acc)\n",
    "        writer.add_summary(smr, e)\n",
    "    writer.close()            \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "jupytext": {
   "formats": "ipynb,py:light",
   "text_representation": {
    "extension": ".py",
    "format_name": "light",
    "format_version": "1.3",
    "jupytext_version": "0.8.1"
   }
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
